\documentclass[12pt]{article}
\usepackage{diagbox}
\usepackage{amsmath}
\usepackage{graphicx} %插入图片的宏包
\usepackage{float} %设置图片浮动位置的宏包
\usepackage{subfigure} %插入多图时用子图显示的宏包
\usepackage{setspace}
\usepackage{xeCJK}
\usepackage{amssymb}
\usepackage[backend=biber, style=authoryear,]{biblatex}
\usepackage{enumerate}
\usepackage{multirow}
\usepackage[rightcaption]{sidecap}
\usepackage{caption}
\usepackage{fontspec}
\usepackage{amsthm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}


\newcommand{\matr}[1]{\mathbf{#1}} % undergraduate algebra version
%\newcommand{\matr}[1]{#1}          % pure math version
%\newcommand{\matr}[1]{\bm{#1}}     % ISO complying version



\setCJKmainfont{NotoSerifTC-Regular.otf} %自行去 google font 下載該字型
\XeTeXlinebreaklocale "zh"             %這兩行一定要加，中文才能自動換行
\XeTeXlinebreakskip = 0pt plus 1pt     %這兩行一定要加，中文才能自動換行
\defaultCJKfontfeatures{AutoFakeBold=6,AutoFakeSlant=.4} %以後不用再設定粗斜
\newCJKfontfamily\Kai{標楷體}           %定義指令\Kai則切換成標楷體
\newCJKfontfamily\Hei{微軟正黑體}       %定義指令\Hei則切換成正黑體
\newCJKfontfamily\NewMing{新細明體}     %定義指令\NewMing則切換成新細明體
\doublespacing
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Application of Nested Logit Model on Recommendation System}
\author{Wei-Yu Fan\thanks{
Graduate student in Department of Economics, National Taiwan University.\\ 
Email address: entrencemania@gmail.com
}, Yu-Chan Chen
} 
\date{May 2024}
\addbibresource{reference.bib}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle
\begin{sloppypar}
\begin{spacing}{0}
\begin{abstract}
\noindent 
We investigated the application of the nested logit (NL) model in the recommendation system (RS). By employing random utility models and the nested logit distribution, we conceptualize consumer interactions with products as stochastic events, modulated by individual preferences across product categories. Subsequently, within the constraints of limited advertising slots, we optimize product assortments to maximize the likelihood of consumer engagement. Moreover, we derive a closed-form solution for this model and furnish accompanying algorithms.
\end{abstract}
\end{spacing}
\begin{tabular}{rl}
\\
\textbf{Keywords:} &Random Utility Model, Nested Logit Model, \\
&Recommendation System, Assortment Optimization.\\
\end{tabular}

\newpage
\section{Introduction}
The random utility model has long been a cornerstone in the recommendation system (RS), enabling the modeling of the relationship between consumers and products. Through this framework, we derive consumer preferences towards products, with the logit model being the most widely recognized, further extended to handle choices involving three or more alternatives, known as the multinomial logit model (MNL). The advantage of the logit family lies in its computationally tractable probabilities and compatibility with regression models. \textcite{mcfadden1977} introduced the generalized extreme value (GEV) distribution, a generalization of the logit model, with the NL model being a specific instance of GEV distribution. Notably, the NL model addresses dependencies among products, a crucial consideration in RS. For instance, in a scenario where advertisements for screens, graphics cards, keyboards, and headphones are placed in four separate slots, such a placement strategy may boost click-through rates for consumers interested in purchasing tech products. However, consumers with no immediate intention to purchase tech items may lack sufficient incentive to engage, highlighting the oversight of not considering the high correlation among these four products.

The NL model is specifically designed to address scenarios where correlations among products are prevalent. Its distinguishing feature lies in its capability to handle dependencies among products by clustering them, thereby making the correlations more apparent and consequently enhancing the effectiveness of RS.

The other benefit of the NL model is related to fairness and diversity. In \textcite{zhao2024}, conventional RS tends to over-recommend popular items, while unpopular items are under-represented. This is called popularity bias (\textcite{DBLP:journals/corr/abs-1907-13286}), and it may lead to several problems. For example, small businesses find it harder to grow, even if they have similar quality to the popular and larger ones. Moreover, these small businesses may drop out of the market, implying the monopolization of the market.
\section{Related Literature}
From conventional choice and behavior models, \textcite{mcfadden1972} proposed the MNL model which depicits the consumers's behavior of choosing among multiple products. An extension of the MNL model is the NL model proposed by \textcite{williams1977}. The NL model is designed to handle the hierachical structure of the choice set, which is common in the real world. The NL model has been widely applied in various fields, such as transportation, marketing, and economics. For example, \textcite{hensher2002} studies the estimation of NL model using data of travellers choosing different transportation modes. Another usecase is the study of assortments optimization probelm in pricing and expected revenue maximization. \textcite{rusmevichientong2009} study that given the price of each product, how to choose the optimal assortment to maximize the expected revenue with the space constraint. The space constarin means that the number of products that can be displayed is limited and each product has a different size. Though this problem is NP-complete, they provide a polynomial time approximation acheme to solve this problem. Following \textcite{rusmevichientong2009}, \textcite{gallego2014} study the assortment optimization problem with different space constraint which limited the space of product in \textbf{each} category. Moreover, \textcite{davis2014} finds out that the complexity and worst-case performance in the assortment optimization problem differs in model settings. The settings are 1. the range of dissimilarity parameter 2. whether consumer may leave after selecting a nest. \footnote{The dissimilarity parameter will be discussed in section 3.4}

From the perspective of machine learning and deep learning, RS are widely used in internet document search, personalized advertisements, and online shopping platforms. The first RS was mentioned by \textcite{1574231873785747328} for algorithm searching among textual documents. \textcite{5731f882-9c11-372e-a87e-2f3238e61d42} used a decision tree model to generate marketing rules that match customer demographics to product categories. The common flow of RS is: 1. Using the available user data to create user embeddings, 2. Computing the item embeddings, 3. Using the dot product of user embeddings and item embeddings to get the relevance score between user-item pairs, 4. Ranking the items from highest to lowest according to the relevance score and selecting the top K items to form a recommendation list, 5. Optionally using a re-ranking model to select the top $\mathrm{K}_2$ items among the top K items.

\section{Fundamental Concepts}
\subsection{Random Utility Model}
Discrete choice model is a fundamental approach in econometrics for depicting consumer behavior. Within this framework, the random utility theory permits consumers to exhibit a degree of randomness in their choices among goods. This randomness elucidates why consumers opt for different products within the same choice set. In this research, we assume consumers are homogeneous and let the representative consumer be the example, the utility derived from goods $i \in \{1, 2\}$ respectively is:
\begin{align*}
    &U_{1} = V_{1} + \epsilon_{1},\\
    &U_{2} = V_{2} + \epsilon_{2}, \qquad (\epsilon_{1}, \epsilon_{2})^T \sim ((0,0)^T, \Sigma).
\end{align*}

$U_{i}$ represents the utility of consumer for product i, $V_{i}$ represents the deterministic utility of product i, and $(\epsilon_{i}, \epsilon_{j})$ represents the random utility of product i and j. Additionally, $(\epsilon_{i}, \epsilon_{j})$ follows a joint distribution with an expected value of 0. Expressing consumer choices with the choice variable $y$, the probability of a consumer choosing product 1 is:
\begin{align*}
    P(y=1) &= P(U_{1} > U_{2}) = P(\epsilon_{1} - \epsilon_{2} > V_{2} - V_{1}) \\ 
    &= \int_{\epsilon_{1} - \epsilon_{2} > V_{2} - V_{1}} f(\epsilon_{1}, \epsilon_{2}) d\epsilon_{1} d\epsilon_{2}.
\end{align*}

\subsection{Logit Model}
If $(\epsilon_{1}, \epsilon_{2}) \overset{\mathrm{iid}}{\sim} \text{type-I Generalized Extreme Value Distribution}$, then this model degenerates into the logit model, and the probability of a consumer choosing product 1 is:
\begin{align*}
    P(y=1) &= \frac{e^{V_{1}}}{e^{V_{1}} + e^{V_{2}}}.
\end{align*}
When we assume $i=2$ is not buying product and let $V_{2}=0$, this model degenerates into binary logit model. The probability of a consumer choosing product 1 is:
\begin{align*}
    P(y=1) &= \frac{e^{V_{1}}}{e^{V_{1}} + 1}.
\end{align*}

Furthermore, if the number of products is generalized to n types, $(\epsilon_{1}, \epsilon_{2}, ..., \epsilon_{n}) \overset{\mathrm{iid}}{\sim} \text{type-I Generalized Extreme Value Distribution}$, then this model degenerates into the MNL model, and the probability of a consumer choosing product i is:
\begin{align*}
    P(y = i) &= P(U_i \geq U_k), \quad \forall k \in \{1, 2, ...,n\}\\
    &= \frac{e^{V_{i}}}{\sum_{k=1}^{n} e^{V_{k}}}.
\end{align*}

\subsection{Generalized Extreme Value Model}
\textcite{mcfadden1977} introduced the generalized extreme value (GEV) distribution, which extends the logit model to a more general form. The advantage of this distribution lies in its ease of computation for choice probabilities when applied in random utility models. As long as the joint cumulative distribution function of random utilities $(\epsilon_{1}, \epsilon_{2}, ..., \epsilon_{n})$ satisfies the following equation:
\begin{equation}
    F(\epsilon_{1}, \epsilon_{2}, ..., \epsilon_{n}) = \exp[-G(e^{-\epsilon_{1}}, e^{-\epsilon_{2}}, ..., e^{-\epsilon_{n}})].
\end{equation}
The sufficient and necessary conditions for aggregate function $G(y_1, y_2, ..., y_n)$ are:
\begin{enumerate}
    \item Nonnegativity
    \item Homogeneity of degree 1
    \item Mixed partial derivatives are continuous and nonpositive for even oreder and nonnegativity for odd order
    \item  $G(y_1, y_2, ..., y_n) \rightarrow \infty$ \text{when} $y_i \rightarrow \infty$
\end{enumerate}

The probability of a consumer choosing product i is:
\begin{align}\label{eqn:the property of GEV model}
    &P(y=i) = e^{V_{i}}\frac{G_i(e^{-V_1},e^{-V_2},...e^{-V_n})}{G(e^{-V_1},e^{-V_2},...e^{-V_n})},\\
    &G_i(y_1, y_2, ..., y_n) := \frac{\partial G(y_1, y_2, ..., y_n)}{\partial y_i}. \nonumber
\end{align}

Let $G(y_1, y_2, ..., y_n)=\sum_{j=1}^{n} y_j$ be the aggregate functionm, the model degenerates into MNL model.
\begin{align*}
    P(y=i) &= e^{V_{i}}\frac{G_i(e^{-V_1},e^{-V_2},...e^{-V_n})}{G(e^{-V_1},e^{-V_2},...e^{-V_n})}\\
    &= \frac{e^{V_{i}}}{\sum_{k=1}^{n} e^{V_{k}}}.
\end{align*}
\subsection{Nested Logit (NL) Model}
The conventional logit model assumes independence among the random utilities of different products, which is an unreasonable assumption in the real world. Therefore, we allow for correlation among products within the same category (nest) while maintaining independence among products of different categories (nests). For example, products such as screens, graphics cards, keyboards, and headphones, all falling under the category of technology, may exhibit correlated random utilities, whereas the random utility of a screen (in technology category) would be independent of that of chocolate (in food category).

Let's assume all products are divided into M categories (nests), with the number of products in the m'th group denoted as $N_m$. Without loss of generality, let's assume $N_1 = N_2 = ... = N_M = N$. In this scenario, a consumer's choice $y \in \textbf{R}^2$ (i.e., y = (i,j) represents the consumer's selection of the j'th item within the i'th category of products).

Constructing a model that fits this scenario using the GEV model yields the NL model. Its definition and properties are as follows:
\begin{definition}[Nested logit (NL) model]
    Under random utility model, if the joint cumulative distribution function of $(\epsilon_{1,1}, \epsilon_{1,2}, ..., \epsilon_{M,N})$ satisfies:
    \begin{align*}
        &F(\epsilon_{1,1}, \epsilon_{1,2}, ..., \epsilon_{M,N})\\
        &=\exp[-G(e^{-\epsilon_{1,1}}, e^{-\epsilon_{1,2}}, ..., e^{-\epsilon_{M,N}})]\\
        &=\exp\{-\sum_{m=1}^{M}[\sum_{n=1}^{N}\exp(-\frac{\epsilon_{m,n}}{\tau_m})]^{\tau_m}\},
    \end{align*}
    this model is called NL model. \\
    The parameters $\tau_m$ are called dissimilarity parameters which are required to satisfy $0 \leq \tau_m \leq 1$ for all $m=1,2,...,M$.\footnote{NL model is consistent with the randomn utility model if this condition is satisfied. \textcite{davis2014} shows that the assortments optimization problem is tractable under this assumption. However, \textcite{borsch1990} shows that local consistency can be preserved even if this condition is violated. }
\end{definition}

\begin{prop}[Probability of nested logit (NL) model]\label{prop:1}
    Under NL model, the probability of consumer choosing item (i,j) is:
    \begin{align*}
        P(y=(i,j)) &= \frac{e^\frac{{V_{i,j}}}{\tau_i}}{\sum_{n=1}^{N} e^\frac{{V_{i,n}}}{\tau_i}} \frac{(\sum_{n=1}^{N} e^\frac{{V_{i,n}}}{\tau_i})^{\tau_i}}{\sum_{m=1}^{M}(\sum_{n=1}^{N} e^\frac{{V_{m,n}}}{\tau_m})^{\tau_m}},
    \end{align*}
    this proposition can be proved by equation \ref{eqn:the property of GEV model}.
\end{prop}

\begin{prop}[Evaluation of probability]\label{prop:2}
    Directly from proposition \ref{prop:1}, 
    \begin{align*}
        P(y=(i,j)) 
        &= \frac{e^\frac{{V_{i,j}}}{\tau_i}}{\sum_{n=1}^{N} e^\frac{{V_{i,n}}}{\tau_i}} \frac{(\sum_{n=1}^{N} e^\frac{{V_{i,n}}}{\tau_i})^{\tau_i}}{\sum_{m=1}^{M}(\sum_{n=1}^{N} e^\frac{{V_{m,n}}}{\tau_m})^{\tau_m}}\\
        &= P(y=(i,j) \mid y=(i,*))P(y=(i,*)),
    \end{align*}
    the first fraction is the conditional probability of choosing item (i,j) given that the consumer chooses category i, and the second fraction is the probability of choosing category i.
\end{prop}

\begin{prop}[Covariance and correlation of nested logit (NL) model]\label{prop:3}
    Under NL model, the covariance and corelation of random utility of \textbf{different} items (i,j) and (k,l) are:
    \begin{align*}
        Cov(\epsilon_{i,j}, \epsilon_{k,l}) = 
        \begin{cases}
            \frac{\pi^2}{6}(1-\tau_i^2), & \text{if i=k} \\
            0, & \text{otherwise}
        \end{cases}
    \end{align*}

    \begin{align*}
        Cor(\epsilon_{i,j}, \epsilon_{k,l}) =
        \begin{cases}
            1-\tau_i^2, & \text{if i=k} \\
            0, & \text{otherwise}
        \end{cases}
    \end{align*}
\end{prop}

\section{Methodologies}
Suppose there are M nests, each with N alternatives. The benefit of the NL model is that the decision is decomposed into two steps: first, the consumer chooses a nest, then the consumer chooses an alternative within the chosen nest. In the scenario of a RS, the consumer clicks on an ad instead of buying a product. Futhermore, assume the consumers are homogeneous which means their deterministic utility are the same. Moreover, the consumer can choose not to click on any ad, which can also be considered as a kind of ad. The "not-click" ad is a special case which is the only choice in the "not-click" nest. Let the 0'th nest be the "not-click" nest; the utility of a consumer clicking on any of these ads is as follows:
\begin{equation}\label{eq: utility}
    U_{i,j} = 
    \begin{cases}
        V_{i,j} + \epsilon_{i,j}, &\text{click j'th ad of i'th nest} \\
        V_0 + \epsilon_0, &\text{not click any ad}.     
    \end{cases}
\end{equation}

Notice that we only observe the consumer's choice, not the consumer's utility. This means that equation \ref{eq: utility} cannot be identified. A common way to solve this problem is to shift the entire model by subtracting $V_0$ (i.e., let $\tilde{U}_{i,j} = U_{i,j} - V_0$).
For readability, we will omit the tilde in the following discussion. Instead of model \ref{eq: utility}, we will discuss the following model:
\begin{equation}\label{eq: utility2}
    U_{i,j} = 
    \begin{cases}
        V_{i,j} + \epsilon_{i,j}, &\text{click j'th ad of i'th nest} \\
        \epsilon_0, &\text{not click any ad}.     
    \end{cases}
\end{equation}

Another issue is the identification of the dissimilarity parameter $\tau_i$. \textcite{heiss} found that if a nest contains only one alternative, the dissimilarity parameter of this nest cannot be identified. In this case, only the "not-click" nest is affected. The solution is rather simple; we set $\tau_0=1$.

Combining the discussions above, the probability of a consumer clicking on ad (i,j) is:
\begin{equation}
    P(y=(i,j)) 
        = \frac{e^\frac{{V_{i,j}}}{\tau_i}}{\sum_{n=1}^{N} e^\frac{{V_{i,n}}}{\tau_i}} \frac{(\sum_{n=1}^{N} e^\frac{{V_{i,n}}}{\tau_i})^{\tau_i}}{1+\sum_{m=1}^{M}(\sum_{n=1}^{N} e^\frac{{V_{m,n}}}{\tau_m})^{\tau_m}},
\end{equation}

and the probability of a consumer not click on any ad is:
\begin{equation}
    P(y=(0,0)) 
        = \frac{1}{1+\sum_{m=1}^{M}(\sum_{n=1}^{N} e^\frac{{V_{m,n}}}{\tau_m})^{\tau_m}}.
\end{equation}

The third issue is that the consumer only views a limited number of ads, which means the consumer can only choose from a subset of all ads. Therefore, we define the set of ads (i.e. assortment) that the consumer can choose from as an exposure matrix $\matr{S} \in \mathbb{R}^{M \times N}$.

\begin{definition}[Exposure Matrix]\label{exposure matrix}
    $\matr{S} \in \mathbb{R}^{M \times N}$ is the exposure matrix if and only if
    \begin{equation*}
        \matr{S_{i,j}} = 
            \begin{cases}
            1, & \text{if ad (i,j) is exposed to consumer} \\
            0, & \text{otherwise}.
            \end{cases}
    \end{equation*}
\end{definition}

Furthermore, let $\matr{s_i} \in \mathbb{R}^{N}$ denote the exposure vector that the consumer can choose from nest i. The relation between $\matr{S}$ and $\matr{s_i}$ is that $\matr{s_i} = \matr{S}^T \matr{e_i}$, where $\matr{e_i} \in \mathbb{R}^{M}$ is a vector with 1 at the i-th position and 0 elsewhere.

In the following sections, we will discuss several cases from simple to complex. The first case is that the consumer is an all-knowing being, which means the consumer can observe any number of ads with ease. The second case is that the consumer is a normal being, and the exposure constraint is that the consumer can observe a limited number of ads per nest. The third case is about the substitute effect within ads. We will discuss the effect of another ad being exposed to the consumer and the impact on the probability of the consumer clicking on the original ad. The fourth case is the more familiar case, where the consumer can only observe a limited number of ads in total.

\subsection{Case 1: All-knowing Consumer}
The goal is to maximize the probability of the consumer click on any ad. In other words, we aim to minimize the probability of consumer not click on any ad. The optimization problem is:
\begin{align}
    \text{Objective funtion:} &\qquad \min_{\matr{S}} P(y=(0,0)) \nonumber \\
    &= \frac{1}{1+\sum_{m=1}^{M}(\sum_{n=1}^{N} \matr{S_{m,n}}e^\frac{{V_{m,n}}}{\tau_m})^{\tau_m}}
\end{align}

To achieve notation simplicity, we define $\matr{H} \in \mathbb{R}^{M \times N}$ as the exponent utility matrix.
\begin{definition}[Exponent Utility Matrix]\label{exponent}
    $\matr{H} \in \mathbb{R}^{M \times N}$ is the exponent utility matrix if and only if 
    \begin{equation*}
        \matr{H_{i,j}} = e^\frac{{V_{i,j}}}{\tau_i}.
    \end{equation*}
\end{definition}

Similarly, we define $\matr{h_i} \in \mathbb{R}^{N}$ as the exponent utility vector of nest i. The relationship between $\matr{H}$ and $\matr{h_i}$ is such that $\matr{h_i} = \matr{H}^T \matr{e_i}$.
Therefore, we can rewrite the optimization problem as follows:
\begin{align}
    \text{Objective funtion:} &\qquad \min_{\matr{S}} P(y=(0,0)) \nonumber \\
    &= \frac{1}{1+\sum_{m=1}^{M}(\matr{h_m}^T \matr{s_m})^{\tau_m}}
\end{align}
The optimal solution $\matr{S}^{\ast}$ is:
\begin{align}\label{optimal}
    \matr{S}^{\ast} &= \arg\min_{\matr{S}} P(y=(0,0)) = \arg\min_{\matr{S}} \frac{1}{1+\sum_{m=1}^{M}(\matr{h_m}^T \matr{s_m})^{\tau_m}} \nonumber \\
    &= \arg\max_{\matr{S}} \sum_{m=1}^{M}(\matr{h_m}^T \matr{s_m})^{\tau_m}.
\end{align}

Since the components of the exponent utility vector $\matr{h_m}$ are all positive, combined with the fact that the components of the exposure vector $\matr{s_m}$ are all binary, the optimal solution should be for the all-knowing consumer to be exposed to all ads to achieve the maximum probability of the consumer clicking on any ad.
\begin{equation}
    \matr{S^{\ast}_{i,j}} = 1, \quad \forall i \in \{1,2,...,M\}, j \in \{1,2,...,N\}.
\end{equation}

\subsection{Case 2: Limited Exposure in each Nest}
Case 2 is case 1 with the exposure consraint. The problem can be written as:
\begin{align} \label{case2}
    \text{Objective funtion:} \qquad &\min_{\matr{S}} P(y=(0,0)) = \frac{1}{1+\sum_{m=1}^{M}(\matr{h_m}^T \matr{s_m})^{\tau_m}},\nonumber \\
    \text{Subject to:} \qquad &\sum_{n=1}^{N}\matr{s_{m,n}} \leq K, \quad \forall m \in \{1,2,...,M\},\\ &\text{where K is some integer less than N}. \nonumber
\end{align}

Case 1 implies that the inner solution (i.e., $\sum_{n=1}^{N}\matr{s_{m,n}} < K$) can never be optimal. Hence, we focus specifically on the bounded solution. The optimal solution is rather simple as well.
Without loss of generality, we can reorder the components of $\matr{H}$ such that $\matr{H_{m,1}} \geq \matr{H_{m,2}} \geq ... \geq \matr{H_{m,N}}, \quad \forall m \in \{1,2,...,M\}$. The optimal solution is:
\begin{equation}
    \matr{S^{\ast}_{m,n}} = 
    \begin{cases}
        1, & \text{if n $\leq$ K} \\
        0, & \text{otherwise}.
    \end{cases}
\end{equation}
The intepratation is that the consumer should be exposed to the K highest exponent utility ads in each nest.

\subsection{Case 3: Substitute Effect}
Here, we discuss the effect of exposing another ad to the consumer and its impact on the probability of the consumer clicking on the original ad. We define the substitute effect of ad (o,p) on ad (i,j) as:
\begin{definition}[Substitute Effect]
    \begin{equation*}
        \mathrm{SE}[(o,p) \rightarrow (i,j)] = P(y=(i,j) \mid \matr{S_{o,p}}=1) - P(y=(i,j) \mid \matr{S_{o,p}}=0).
    \end{equation*}
\end{definition}

The substitute effect can be calculated by the following formula 
\begin{align*}
    &P(y=(i,j) \mid \matr{S_{o,p}}=0) =  \frac{\matr{H_{i,j}}}
    {\matr{h_i}^T \matr{s_i}} \frac{(\matr{h_i}^T \matr{s_i})^{\tau_i}}{1+\sum_{m=1}^{M} (\matr{h_m}^T\matr{s_m})^{\tau_m}}\\
    &P(y=(i,j) \mid \matr{S_{o,p}} = 1)=
    \begin{cases}
        \frac{\matr{H_{i,j}}}
        {\matr{h_i}^T \matr{s_i}} \frac{(\matr{h_i}^T \matr{s_i})^{\tau_i}}{1+\sum
        \limits_{m=1, m \neq o}^{M} (\matr{h_m}^T\matr{s_m})^{\tau_m}+(\matr{h_o}^T \matr{s_o}+\matr{H_{o,p}})^{\tau_o}}, &o \neq i,\\
        \frac{\matr{H_{i,j}}}
        {\matr{h_i}^T \matr{s_i}+\matr{H_{o,p}}} \frac{(\matr{h_i}^T \matr{s_i}+\matr{H_{o,p}})^{\tau_i}}{1+\sum\limits_{m=1, m \neq o}^{M} (\matr{h_m}^T\matr{s_m})^{\tau_m}+(\matr{h_o}^T \matr{s_o}+\matr{H_{o,p}})^{\tau_o}}, &o = i.
    \end{cases}
\end{align*}

Assume $\matr{H_{o,p}}$ is rather small, the first order Taylor expansion of\\ $P(y=(i,j) \mid \matr{S_{o,p}} = 1)$ at $\matr{H_{o,p}}=0$ is:
\begin{align}\label{p proun}
    &\quad P(y=(i,j) \mid \matr{S_{o,p}} = 1) \nonumber\\
    &\approx
    \begin{cases}
        P(y=(i,j) \mid \matr{S_{o,p}} = 0)[1-\frac{\matr{H_{o,p}}}{\matr{h_o}^T \matr{s_o}}\frac{\tau_o(\matr{h_o}^T \matr{s_o})^{\tau_o}}{1+\sum_{m=1}^{M} (\matr{h_m}^T\matr{s_m})^{\tau_m}}], &o \neq i,\\
        %P(y=(i,j) \mid \matr{S_{o,p}} = 0)[1-\frac{\matr{H_{o,p}}}{\matr{h_o}^T \matr{s_o}}(1-\frac{\tau_o(1+\sum\limits_{m=1, m \neq o}^{M} (\matr{h_m}^T\matr{s_m})^{\tau_m})}{1+\sum_{m=1}^{M} (\matr{h_m}^T\matr{s_m})^{\tau_m}})], &\quad o = i.
        P(y=(i,j) \mid \matr{S_{o,p}} = 0)[1-\frac{\matr{H_{o,p}}}{\matr{h_o}^T \matr{s_o}}(\frac{\tau_o(\matr{h_o}^T\matr{s_o})^{\tau_o}}{1+\sum_{m=1}^{M} (\matr{h_m}^T\matr{s_m})^{\tau_m}}+(1-\tau_o))], &o = i.
    \end{cases}
\end{align}

From equation \ref{p proun}, we can derive the substitute effect of ad (o,p) on ad (i,j) as:
\begin{equation}\label{se}
\begin{aligned}
    &\quad \mathrm{SE}[(o,p) \rightarrow (i,j)] = P(y=(i,j) \mid \matr{S_{o,p}}=1) - P(y=(i,j) \mid \matr{S_{o,p}}=0)  \\
    &\approx 
    \begin{cases}
        -P(y=(i,j) \mid \matr{S_{o,p}} = 0)\frac{\matr{H_{o,p}}}{\matr{h_o}^T \matr{s_o}}\frac{\tau_o(\matr{h_o}^T \matr{s_o})^{\tau_o}}{1+\sum_{m=1}^{M} (\matr{h_m}^T\matr{s_m})^{\tau_m}}, &o \neq i,\\
        -P(y=(i,j) \mid \matr{S_{o,p}} = 0)\frac{\matr{H_{o,p}}}{\matr{h_o}^T \matr{s_o}}[\frac{\tau_o(\matr{h_o}^T\matr{s_o})^{\tau_o}}{1+\sum_{m=1}^{M} (\matr{h_m}^T\matr{s_m})^{\tau_m}}+(1-\tau_o)], &o = i.
    \end{cases}
\end{aligned}
\end{equation}

The result is actually intuitive. First, the substitute effect of ad (o,p) on ad (i,j) is negative in both cases, which means that the probability of a consumer clicking on ad (i,j) decreases when another ad is exposed to the consumer. This makes sense because in the NL model, all the ads are substitutes for each other with respect to probability. Second, the magnitude of the substitute effect is larger (the $1-\tau_o$ term in equation \ref{se}) when the old ad shares the same nest with the new ad. This is reasonable because the ads in the same nest are more similar to each other, which means the consumer is more likely to substitute the old ad with the new one. For example, the substitute effect of a new iPhone ad on a Samsung mobile ad is larger than the substitute effect of a new iPhone ad on a cereal ad due to the fact that the iPhone and Samsung mobile are both in the smartphone category, but cereal isn't.

\subsection{Case 4: Limited Exposure in Total}
Case 4 is case 2 with a different exposure consraint. The problem can be written as:
\begin{align} \label{case4}
    \text{Objective funtion:} \qquad &\min_{\matr{S}} P(y=(0,0)) = \frac{1}{1+\sum_{m=1}^{M}(\matr{h_m}^T \matr{s_m})^{\tau_m}},\nonumber \\
    \text{Subject to:} \qquad &\sum_{m=1}^{M}\sum_{n=1}^{N}\matr{S_{m,n}} \leq K,\ K \in \mathbb{N},\ K \leq M \times N.
\end{align}

The constraint can be written as $\sum_{m=1}^{M}\matr{s_m}^T\matr{s_m} \leq K,$ which seems like the familiar L2 regularization in machine learning. The difference is that the L2 regularization is a continuous constraint while the constraint in the random utility problem is a discrete constraint. This kind of problem is called the knapsack problem in combinatorial optimization and
\begin{lemma}
    Knapsack problem is NP-complete.
\end{lemma}
\begin{proof}
    Refer to \textcite{garey1990}.
\end{proof}
Nonetheless, in our setting, the optimal solution $\matr{S}^{\ast}$ is P problem.

In the first step, sort the components of each row of $\matr{H}$ in descending order i.e., $\matr{H_{m,1}} \geq \matr{H_{m,2}} \geq ... \geq \matr{H_{m,N}}, \quad \forall m \in \{1,2,...,M\}$. To proceed further, we need the following lemma.
\begin{lemma}[Monotonicity of Choice]\label{lemma1}
    $\matr{S^{\ast}}$ is the optimal solution. If $\matr{S^{\ast}_{i,j}} = 1$, then
    \begin{equation*}
        \matr{S^{\ast}_{i,j-1}} = 1
    \end{equation*}
\end{lemma}

\begin{proof}
    The proof is by contradiction. Suppose $\matr{S^{\ast}_{i,j-1}} = 0$, then we can construct a new solution $\matr{S'}$ by setting $\matr{S'_{i,j}} = 0$ and $\matr{S'_{i,j-1}} = 1$. Since the objective function is the same as case 1, we can rewrite the objective function as 
    \begin{equation}
        \text{Alternative Objective funtion:} \qquad \max_{\matr{S}} \sum_{m=1}^{M}(\matr{h_m}^T \matr{s_m})^{\tau_m}.
    \end{equation}
    The difference between alternative value functions achieved by $\matr{S'}$ and $\matr{S^{\ast}}$ is:
    \begin{equation*}
    \begin{aligned}
        &\quad \sum_{m=1}^{M}(\matr{h_m}^T \matr{s'_m})^{\tau_m} - \sum_{m=1}^{M}(\matr{h_m}^T \matr{s^{\ast}_m})^{\tau_m} \\
        &= (\matr{h_i}^T \matr{s'_i})^{\tau_i} - (\matr{h_i}^T \matr{s^{\ast}_i})^{\tau_i} \\
        &= (\sum\limits_{n \neq j, n \neq j-1}^{N} \matr{H_{i,n}} \matr{S'_{i,n}}+\matr{H_{i,j-1}})^{\tau_i} - (\sum\limits_{n \neq j, n \neq j-1}^{N} \matr{H_{i,n}} \matr{S^{\ast}_{i,n}}+\matr{H_{i,j}})^{\tau_i}\\
        &= (\sum\limits_{n \neq j, n \neq j-1}^{N} \matr{H_{i,n}} \matr{S^{\ast}_{i,n}}+\matr{H_{i,j-1}})^{\tau_i} - (\sum\limits_{n \neq j, n \neq j-1}^{N} \matr{H_{i,n}} \matr{S^{\ast}_{i,n}}+\matr{H_{i,j}})^{\tau_i}> 0.
    \end{aligned}
    \end{equation*}
    Therefore, the alternative solution $\matr{S'}$ is better than the optimal solution $\matr{S^{\ast}}$, which contradicts the assumption that $\matr{S^{\ast}}$ is the optimal solution.
\end{proof}

\begin{lemma}[Bounded Constraint]\label{lemma2}
    Optimal solution $\matr{S^{\ast}}$ always satisfies the bounded constraint i.e.
    \begin{equation*}
        \sum_{m=1}^{M}\sum_{n=1}^{N}\matr{S^{\ast}_{m,n}} = K.
    \end{equation*}
\end{lemma}
\begin{proof}
    This is proof by contradiction. Suppose $\sum_{m=1}^{M}\sum_{n=1}^{N}\matr{S^{\ast}_{m,n}} < K$, then we can construct a new solution $\matr{S'}$ by setting $\matr{S'_{i,j}} = 1$ where $\matr{S^{\ast}_{i,j}} = 0$. Using the alternative objective function in lemma \ref{lemma1}, we can show that the alternative solution $\matr{S'}$ is better than the optimal solution $\matr{S^{\ast}}$, which contradicts the assumption that $\matr{S^{\ast}}$ is the optimal solution.
\end{proof}

By Lemma \ref{lemma1}, we can conclude that the optimal solution $\matr{S^{\ast}}$ is a matrix in which the components are all 1 on the left side and 0 on the right side. The number of 1's is exactly K, as proven by Lemma \ref{lemma2}. The last piece of the puzzle is to find the distribution of 1's in each row. To achieve this, we need to construct a new variable $\Delta_{i,j}$, which denotes the increment of the alternative objective function when $\matr{S_{i,j}}$ is changed from 0 to 1. By Lemma \ref{lemma1}, we only need to consider $\matr{S_{i,j}}$ when $\matr{S_{i,1}}, \matr{S_{i,2}}, ..., \matr{S_{i,j-1}}$ are all 1. Therefore, the formal definition of $\Delta_{i,j}$ is:
\begin{definition}[Increment Variable]\label{increment}
    \begin{align*}
    \Delta_{i,j} = 
    \begin{cases}
        (\sum\limits_{n=1}^{j} \matr{H_{i,n}})^{\tau_i} - (\sum\limits_{n=1}^{j-1} \matr{H_{i,n}})^{\tau_i}, &\text{if j $\neq$ 1},\\
        \matr{H_{i,1}}^{\tau_i}, &\text{if j = 1}.
    \end{cases}
    \end{align*}
\end{definition}

Given that $\tau_m \leq 1, \forall m \in \{1,2,...,M\}$, the increment variable $\Delta_{i,j}$ is non-increasing in j. Therefore, the optimal solution $\matr{S^{\ast}}$ is determined by the first K largest increment variables. The optimal solution $\matr{S^{\ast}}$ is:
\begin{align}
    \matr{S^{\ast}_{i,j}} = 
    \begin{cases}
        1, &\text{if $\Delta_{i,j}$ is one of the K largest increment variables},\\
        0, &\text{otherwise}.
    \end{cases}
\end{align}

The complete algorithm is as follows:
\begin{enumerate}
    \setcounter{enumi}{-1}
    \item Identify the nest structure of the model, the deterministic utility of ads, and the dissimilarity parameters $\tau_i$.\footnote{The nest structure can be identified by the domain knowledge. Besides, \textcite{hausman1978} proposed Hausman's specification test which is used to identify the worngly classified products. The deterministic utility and $\tau_i$ can be identified by the sequential estimation proposed by \textcite{train}.}
    \item Calculate the exponent utility matrix $\matr{H}$ and sort the components of each row in descending order.
    \item Calculate the increment variables $\Delta_{i,j}$.
    \item Find the optimal solution $\matr{S^{\ast}}$ by selecting the first K largest increment variables across all $\Delta_{i,j}$.
\end{enumerate}

The time complexity of the algorithm is $O(MN)$, which is linear to the number of total ads. The algorithm is easy to implement and interpret. The results can be used in the RS to maximize the probability of a consumer clicking on any ad.

\section{Diversity and Fairness}
According to \textcite{zhao2024}, diversity and fairness are two different concepts with similar goals. Fairness focuses on:
\begin{enumerate} \item Popularity Bias: The exposure of similar items should be fair. \item Quality Discrepancy: The recommendation quality for different users/groups should be similar. \item Discriminator Performance: The recommendation results should not take into account sensitive attributes (e.g., gender or sexual orientation). \end{enumerate}

On the other hand, diversity is categorized into two types: \begin{enumerate} \item Individual Diversity: The recommendation list should contain a variety of items. \item Aggregate Diversity: The recommendation list varies across different users/groups, which means RS is able to recommend less popular items to users. \end{enumerate}

There are two types of metrics to measure diversity and fairness. The first one measures the average distance of item embedding pairs within a recommendation list, i.e., Intra-List Diversity (ILD). \textcite{10.1145/1060745.1060754} started from a reverse perspective and proposed Intra-List Similarity (ILS), choosing among items with the least similarity. \textcite{10.1145/2645710.2645743} criticized the distance metric due to inconsistency. They leveraged genre information and proposed a novel metric called $\mathrm{BinomDiv(\matr{S})} = \mathrm{Coverage(\matr{S})}\times\mathrm{NonRed(\matr{S})}$. Coverage is the number of genres in the recommendation list, and NonRed (i.e., non-redundancy) is the number of genres that are not repeated in the recommendation list. As for aggregate diversity, the most common metrics are the total number of unique items, Shannon entropy, and the Gini index.

\begin{definition}[Intra-List Diversity]
    \begin{align*}
        ILD(\matr{S}) = \frac{1}{|\matr{S}|(|\matr{S}|-1)}\sum_{\matr{S}_{i',j'}\neq 0}\sum_{\substack{\matr{S}_{i,j}\neq 0\\ (i,j)\neq(i',j')}}d(i, j, i', j'), \\
        \text{where $d(i, j, i', j')$ is the distance between item (i, j) and item (i', j').}
    \end{align*}
\end{definition}

\begin{definition}[Shannon Entropy]
    \begin{align*}
        &H = -\sum_{i,j}^{N,M} freq(i,j) \log freq(i,j),\\
        &\text{where \textit{freq(i,j)} is the frequency of item (i,j) in the lists across users.}
    \end{align*}
\end{definition}

To achieve diversity, re-ranking is a common approach for RS. By combining the relevance score with the diversity score, the system re-ranks the recommendation list. Adding items one by one with a greedy algorithm, it can easily find a suboptimal solution. Many researchers have adapted this method (\textcite{10.1145/1772690.1772780}, \textcite{10.1007/3-540-44593-5_25}). Likewise, learning-to-rank is another approach to achieve diversity by adding a regularization term to the loss function. One additional approach utilizes fusion-based models to achieve diversity. Fusion-based models aggregate multiple recommendation scores to generate a recommendation list. \textcite{10.1145/2365952.2365962} combined the scores by weighted sum, then used the Strength Pareto Evolutionary Algorithm to optimize the weights.

\section{Conclusion}
In this paper, we aim to maximize the opportunity for a representative consumer to click on any ads. We first discuss the all-knowing consumer case and show that the optimal solution is to expose the consumer to all ads. Then we discuss the limited exposure in each nest case and show that the optimal solution is to expose the consumer to the K highest exponent utility ads in each nest. We also discuss the substitute effect of ads and show that the probability of a consumer clicking on an ad decreases when another ad is exposed to the consumer. The magnitude of the substitute effect is larger when the old ad shares the same nest with the new ad. Finally, we discuss the limited exposure in total case and show that the optimal solution is to expose the consumer to the K highest increment variables across all ads. The optimal solution is determined by the first K largest increment variables. An algorithm is provided to find the optimal solution. The results can be used in the RS to maximize the probability of a consumer clicking on any ad.

However, there are some limitations in our paper. First, we assume consumers are homogeneous. The advantage of this assumption is data sufficiency because researchers can use all of the consumers' data to estimate the parameters. The drawback is the loss of flexibility because all of the consumers are exposed to the same ad set (i.e. assortment). The potential solution may lie in Bayesian statistics. The result from the nested model can be treated as a prior, and the user's history data can be treated as a likelihood function used to update the recommendation ad set over time. Second, model misspecification is another issue. Since we use the NL model, every ad is in exactly one nest, unlike the real world. To relax this assumption, one may adopt a more general model like the cross-nested logit (CNL) model \textcite{vovsha}. Third, the model is static. The optimal solution is determined by the current utility of ads. The ideal model should be able to capture the time-varying utility of ads. The time-varying and customized RS is a potential research direction, and Bayesian statistics may be a good tool to solve this problem.

In conclusion, we proposed a model to improve the click-through rate of ads in the RS. The advantages of our model are 1. backed up by the random utility model, 2. consider the dependencies among similar ads, 3. have closed form solution, 4. the time complexity is linear to to number of total ad, and 5. easy to interpretate. The disadvantage of our model are 1. homogeneous consumer assumption which leads to no customization, 2. model and structure specification, and 3. static model.

\printbibliography


\end{sloppypar}
\end{document}